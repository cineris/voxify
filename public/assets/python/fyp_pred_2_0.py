# -*- coding: utf-8 -*-
"""FYP_Pred_2.0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cb0QFLfScchYpavzNuVc86B6L6bdOMB0
"""
#Normalization of datasets

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import os
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Set the path to the directory containing the CSV files
dir_path = '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/DataSets/'

# Set the output directory for the scaled CSV files
output_dir = '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_Datasets'

# Create the output directory if it doesn't already exist
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# Loop over each CSV file in the input directory
for filename in os.listdir(dir_path):
    if filename.endswith('.csv'):
        # Load the CSV file into a Pandas DataFrame
        filepath = os.path.join(dir_path, filename)
        df = pd.read_csv(filepath)

        # Create a new instance of the MinMaxScaler object for X variables
        scaler_X = MinMaxScaler()
        # Create a new instance of the MinMaxScaler object for Y variable
        scaler_Y = MinMaxScaler()

        # Scale the X variables
        columns_to_scale_X = ['YTS', 'WIP', 'APPROVED']
        df[columns_to_scale_X] = scaler_X.fit_transform(df[columns_to_scale_X])

        # Scale the Y variable
        columns_to_scale_Y = ['Day']
        if filename != 'DataSet12.csv':
            df[columns_to_scale_Y] = scaler_Y.fit_transform(df[columns_to_scale_Y])

        # Write the scaled DataFrame to a new CSV file in the output directory
        output_filepath = os.path.join(output_dir, filename)
        df.to_csv(output_filepath, index=False)

#Dividing datasets for training and testing
# Path to the directory containing your datasets
data_dir = '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets'

# Create subdirectories for the train and test files
train_dir = os.path.join(data_dir, 'train_files')
test_dir = os.path.join(data_dir, 'test_files')

for directory in [train_dir, test_dir]:
    if not os.path.exists(directory):
        os.makedirs(directory)

# Loop through all CSV files in the directory
for filename in os.listdir(data_dir):
    if filename.endswith('.csv') and filename != 'DataSet12.csv':
        # Load the dataset into a Pandas DataFrame
        df = pd.read_csv(os.path.join(data_dir, filename))

        # Split the dataset into independent (X) and dependent (y) variables
        X = df.drop('Day', axis=1)
        y = df['Day']

        # Split the dataset into training and test sets
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Save the training and test sets in the appropriate subdirectories
        train_filename = filename.replace('.csv', '_train.csv')
        test_filename = filename.replace('.csv', '_test.csv')

        train_df = pd.concat([X_train, y_train], axis=1)
        test_df = pd.concat([X_test, y_test], axis=1)

        train_df.to_csv(os.path.join(train_dir, train_filename), index=False)
        test_df.to_csv(os.path.join(test_dir, test_filename), index=False)

#Model Build, Fit and Predict
# Define the path of the folder containing the CSV files
folder_path = '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets/train_files/'

# Load all CSV files in the folder and concatenate them into one DataFrame
dfs = []
for file in os.listdir(folder_path):
    if file.endswith('.csv') and not file.endswith('test.csv'):
        file_path = folder_path + file
        df = pd.read_csv(file_path)
        dfs.append(df)
train_data = pd.concat(dfs, ignore_index=True)

X_train = train_data[['YTS', 'WIP', 'APPROVED']]
y_train = train_data['Day']

model = LinearRegression().fit(X_train, y_train)

# Load all test datasets into a list
test_files = ['/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets/test_files/DataSet1_test.csv', '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets/test_files/DataSet2_test.csv', '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets/test_files/DataSet3_test.csv', '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets/test_files/DataSet4_test.csv', '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets/test_files/DataSet5_test.csv', '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets/test_files/DataSet6_test.csv', '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets/test_files/DataSet7_test.csv', '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets/test_files/DataSet8_test.csv', '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets/test_files/DataSet9_test.csv', '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets/test_files/DataSet10_test.csv', '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets/test_files/DataSet11_test.csv']

# Loop through each test dataset, make predictions, and store the results
for test_file in test_files:
  test_data = pd.read_csv(test_file)
  X_test = test_data[['YTS', 'WIP', 'APPROVED']]
  y_test = test_data['Day']
  y_pred = model.predict(X_test)
  
  # Do something with the predictions here
  # For example, you can print the predicted values
  print(y_pred)

#Validating

mse = mean_squared_error(y_test, y_pred)
print('Mean squared error: ', mse)

r2 = model.score(X_test, y_test)
print("R-squared value:", r2)

# Set the path to the directory containing the CSV files
data_dir = '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets'

# Set the path to the CSV file to be modified
csv_file = 'DataSet12.csv'

# Load the CSV file into a Pandas DataFrame
csv_path = os.path.join(data_dir, csv_file)
df = pd.read_csv(csv_path)

# Write the modified DataFrame back to the CSV file
df.to_csv(csv_path, index=False)

#Predicting with New Dataset

# Load and preprocess the new data
new_data = pd.read_csv('/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets/DataSet12.csv')
# Apply the same preprocessing steps you used on your training and test sets

# Make predictions on the new data
Predicted_Day = model.predict(new_data)

# Create a new DataFrame that contains the original data and the predicted values
new_data_with_predictions = pd.concat([new_data, pd.DataFrame(Predicted_Day, columns=['Day'])], axis=1)

# Insert the 'Predicted Day' column after the 'Day' column
new_data_with_predictions.insert(0, 'Day', new_data_with_predictions.pop('Day'))

# Print the new DataFrame
print(new_data_with_predictions)

# Set the output directory for the predictions CSV file
output_dir = '/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/Normal_DataSets/pred_output'

# Create the predictions directory if it doesn't already exist
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# Write the new DataFrame to a CSV file in the predictions directory
output_filepath = os.path.join(output_dir, 'new_data_with_predictions.csv')
new_data_with_predictions.to_csv(output_filepath, index=False)

from pickle import dump

# save the model
dump(model, open('/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/load_files/model.pkl', 'wb'))
# save the scaler X
dump(scaler_X, open('/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/load_files/scalerX.pkl', 'wb'))
# save the scaler
dump(scaler_Y, open('/Users/phrophecyreaper/Desktop/MPSTME/SEMESTER 8/FYP/main/output/load_files/scaler_Y.pkl', 'wb'))

#Reverting Predictions to Original
# Split the DataFrame into two parts based on the columns that need to be transformed differently
Y = ['Day']
X = ['YTS', 'WIP', 'APPROVED']
Ydata = new_data_with_predictions[Y]
Xdata = new_data_with_predictions[X]

# Use the respective scaler for each part to invert the scaling
Ydata = pd.DataFrame(scaler_Y.inverse_transform(Ydata), columns=Y)
Xdata = pd.DataFrame(scaler_X.inverse_transform(Xdata), columns=X)

# Combine the two parts back into a single DataFrame
original_with_predictions = pd.concat([Ydata, Xdata, pd.DataFrame(Predicted_Day, columns=['Predicted Day'])], axis=1)

# Print the new DataFrame
print(original_with_predictions)